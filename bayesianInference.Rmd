```{r echo = FALSE}
library(distill)
```

---
title: "Bayesian inference in computational intelligence"
author: 
  - name: "Rodrigo Pereira Cruz"
    email: pereirarodrigocs@gmail.com
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

---

This is a notebook used for studying Bayesian inference in computational intelligence, which is focused on its theoretical applications. The R programming language was chosen for the practical part of this project, as its orientation towards statistical analysis, ease of use and modular nature makes it well suited for this kind of task.  

---

# 1. Introduction

***

Bayes' theorem is a fundamental part of probability and statistics. It is deeply tied to conditional probability, often expressed as $P(A | B)$ and read as the probability of A given B. Bayesian statistics relies on having prior probabilities, which constitutes the currently known information, and calculating posterior probabilities based on the prior and likelihood. This is a constant process, where the prior probabilities are constantly updated. Bayes' theorem is usually defined as

<br>

$$P(A | B) = \frac{P(B | A) \space P(A)}{P(B)}$$

<br>

where

<br>

* $P(A | B)$ = posterior probability;
* $P(B | A)$ = likelihood;
* $P(A)$ = prior probability;
* $P(B)$ = marginal probability.

<br>

Oftentimes, this definition is expanded upon when $P(B)$ isn't clearly defined:

<br>

$$\begin{align}
    P(A | B) &= \frac{P(B | A) \space P(A)}{P(B)} \\
             &= \space \frac{P(B | A) \space P(A)}{P(B | A) \space P(A) + P(B | \neg A) \space P(\neg A)}
\end{align}$$

<br>

When it comes to computing, Bayes' theorem is already popular in the field of machine learning, where it's known as the naive Bayes algorithm and is used as a classifier. A simple usage can be seen below:

```{r}

# A simple use of the naive Bayes model for classification
# The model efficiently classifies 3 types of iris flowers: setosa, versicolor and virginica

library(e1071)
library(caret)

data("iris")

iris_dataset <- as.data.frame(iris)
bayes <- naiveBayes(Species ~., data = iris_dataset)

# Check the model
bayes

bayes_predictions <- predict(bayes, iris_dataset)

# Checking the predictions, the confusion matrix and the accuracy

table(bayes_predictions, iris_dataset$Species)

confusionMatrix(iris$Species, bayes_predictions)
```
---

# 2. Continuous random variables

***

Although the usage of probability mass functions (PMFs) is common when dealing with probability distributions, Bayesian inference often deals with continuous variables, which requires the use of probability density functions (PDFs).

When it comes to PDFs, it's impossible to use a precise probability value for the event we're interested in - calculating the **exact** probability of raining exactly 2mm in a week, for example, is impractical. When situations like this arise, the need of using ranges for our values is made absolutely necessary and, thus, dealing with continuous variables becomes a matter of calculating the area between inferior and superior ranges. Mathematically, this can be expressed as

<br>

$$P(a \leq X \leq b) = \int_{a}^{b} f_X(x)dx = F(b) - F(a) $$

<br>

This is, of course, only a general overview, as some of the most common continuous distributions - normal, uniform, beta and gamma - are different and are used for different tasks. However, what all of them share in Bayesian statistics is the presence of prior elicitation, which is a belief in one's data distribution. For Bayesians, this elicitation expresses their belief in terms of personal probabilities and must adhere to the laws or probability (e.g. having a probability of 150% of winning a lottery is invalid for a prior elicitation). Thus, given a Bayesian has this belief in their distribution, we must deal with knowing the probability of success of that data.

In a distribution, the probability of success, known as $p$, is not usually known. For example, when tossing a coin, the probability of heads is, for a balanced coin, 0.5 or $\frac{1}{2}$. However, we can't know if a coin is balanced, thus we **predict** that this value, our $p$, must be closer to 0.5 than 0 or 1. A Bayesian will express their belief in a particular value of $p$ through a probability distribution, with the **beta family** being a popular choice, usually being defined, mathematically, as

<br>

$$p \sim beta(\alpha, \beta)$$

<br>

whose PDF is

<br>

$$f(p) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)  \Gamma(\beta)} p^{\alpha - 1} (1 - p)^{\beta - 1}$$

<br>

where $0 \leq p \leq 1, \alpha > 0, \beta > 0$ and $\Gamma$ is a factorial:

<br>

$$\Gamma(n) = (n - 1)! = (n - 1) \times (n - 2) \times ... \times 1$$

<br>

where $n$ is the number of trials.

<br>

When it comes to computing, it's possible to write a very simple R script that generates a beta distribution, with multiple options being available. An example is shown below:

```{r}
# Generating a beta distribution out of a sequence of values

values <- seq(0, 1, 0.02)

# dbeta gives us a PDF
# shape1 = alpha and shape2 = beta

beta_dist <- dbeta(values, shape1 = 2, shape2 = 3)

# Plotting the results

plot(beta_dist, 
     main = "A beta distribution",
     xlab = "x", 
     ylab = "y",
     col = "blue",
     type = "o")
```

---

# 3. Bayesian decision making and loss functions

***

The posterior probability is the basis of any Bayesian inference, as it's essentially updated knowledge given it incorporates prior information with new data. However, we might want to express a credible interval as our inference, which makes using posterior distributions difficult - because of this, we are now dealing with decision theory and, thus, must make use of loss functions for optimization. There are usually three loss functions that are used, which are:

<br>

* **Linear** = uses a median as its best estimate;
* **Quadratic** = uses a mean as its best estimate;
* **0/1** = uses a mode as its best estimate.

<br>

Starting with 0/1 loss, the goal is to check if each value in the posterior distribution is equal to, or different than, an estimate. Should the value be equal to your estimate, there will be no loss; otherwise, a loss of 1 point will happen. Mathematically, this function is defined as

<br>

$$L_{0, i}(0, g) = \begin{cases}
                      0 & if \space g = x_i \\
                      1 & otherwise
                   \end{cases}$$
                   
<br>

where $g$ is our guess or an estimate. The total loss is defined as

<br>

$$L_0 = \sum_i L_{0, i}(0, g)$$

<br>

A quick example is given below, where we have some random data, our estimate is 12 and we're using the 0/1 loss:

<br>

<style>
table th:first-of-type {
    width: 30%;
}
table th:nth-of-type(2) {
    width: 20%;
}
table th:nth-of-type(3) {
    width: 50%;
}
</style>

$i$ | $x_i$ | $L0: 0/1$
:--:|:-----:|:---------:
 1  |   2   |   1
 2  |   6   |   1
 3  |   3   |   1
 4  |   12  |   0
 5  |   14  |   1
 -  | **Total** |   4
 
<br>